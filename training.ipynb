{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1pY7ZB98CQBwauZZpDKnVGpyzK4hNdL09","authorship_tag":"ABX9TyM7QQmO165lGmLBHeGFCzDu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMnDwiv4WYQw","executionInfo":{"status":"ok","timestamp":1754293684843,"user_tz":-330,"elapsed":14091,"user":{"displayName":"Megha Shyam","userId":"08441739143667292717"}},"outputId":"235f584c-6825-48fe-9e4d-a08c1e874a1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset initialized with 56 samples\n","Colors: ['blue', 'cyan', 'green', 'magenta', 'orange', 'purple', 'red', 'yellow']\n","Color mapping: {'blue': 0, 'cyan': 1, 'green': 2, 'magenta': 3, 'orange': 4, 'purple': 5, 'red': 6, 'yellow': 7}\n","Sample keys: dict_keys(['input_image', 'color_onehot', 'color_idx', 'color_name', 'output_image', 'input_filename', 'output_filename'])\n","Input image shape: torch.Size([3, 256, 256])\n","Output image shape: torch.Size([3, 256, 256])\n","Color onehot shape: torch.Size([8])\n","Color name: cyan\n","Color index: 1\n","\n","Batch input shape: torch.Size([4, 3, 256, 256])\n","Batch output shape: torch.Size([4, 3, 256, 256])\n","Batch color onehot shape: torch.Size([4, 8])\n"]}],"source":["import json\n","import os\n","from typing import Dict, List, Tuple, Optional\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import numpy as np\n","\n","\n","class PolygonColorDataset(Dataset):\n","    def __init__(self,\n","                 data_json_path: str,\n","                 input_dir: str,\n","                 output_dir: str,\n","                 image_size: int = 256,\n","                 augmentations: Optional[transforms.Compose] = None,\n","                 color_to_idx: Optional[Dict[str, int]] = None):\n","\n","        self.input_dir = input_dir\n","        self.output_dir = output_dir\n","        self.image_size = image_size\n","        self.augmentations = augmentations\n","\n","        # Load data from JSON\n","        with open(data_json_path, 'r') as f:\n","            self.data = json.load(f)\n","\n","        # Create color mappings\n","        if color_to_idx:\n","            self.color_to_idx = color_to_idx\n","            self.colors = sorted(list(self.color_to_idx.keys()))\n","        else:\n","            self.colors = sorted(list(set(item['colour'] for item in self.data)))\n","            self.color_to_idx = {color: idx for idx, color in enumerate(self.colors)}\n","\n","        self.num_colors = len(self.colors)\n","\n","        print(f\"Dataset initialized with {len(self.data)} samples\")\n","        print(f\"Colors: {self.colors}\")\n","        print(f\"Color mapping: {self.color_to_idx}\")\n","\n","        # Define transforms\n","        self.transform = transforms.Compose([\n","            transforms.Resize((image_size, image_size)),\n","            transforms.ToTensor(),\n","        ])\n","\n","        # Normalize to [-1, 1] for better training stability\n","        self.normalize = transforms.Normalize([0.5], [0.5])\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","\n","        # Load input polygon image\n","        input_path = os.path.join(self.input_dir, item['input_polygon'])\n","        input_image = Image.open(input_path).convert('RGB')\n","\n","        # Load target output image\n","        output_path = os.path.join(self.output_dir, item['output_image'])\n","        output_image = Image.open(output_path).convert('RGB')\n","\n","        # Apply transforms\n","        input_tensor = self.transform(input_image)\n","        output_tensor = self.transform(output_image)\n","\n","        # Normalize to [-1, 1]\n","        input_tensor = self.normalize(input_tensor)\n","        output_tensor = self.normalize(output_tensor)\n","\n","        # Get color information\n","        color_name = item['colour']\n","        color_idx = self.color_to_idx[color_name]\n","\n","        # Create one-hot encoding for color\n","        color_onehot = torch.zeros(self.num_colors)\n","        color_onehot[color_idx] = 1.0\n","\n","        # Apply augmentations if provided\n","        if self.augmentations:\n","            # Apply same augmentation to both input and output\n","            seed = np.random.randint(2147483647)  # make a seed with numpy generator\n","\n","            # Apply to input\n","            torch.manual_seed(seed)\n","            input_tensor = self.augmentations(input_tensor)\n","\n","            # Apply to output\n","            torch.manual_seed(seed)\n","            output_tensor = self.augmentations(output_tensor)\n","\n","        return {\n","            'input_image': input_tensor,\n","            'color_onehot': color_onehot,\n","            'color_idx': color_idx,\n","            'color_name': color_name,\n","            'output_image': output_tensor,\n","            'input_filename': item['input_polygon'],\n","            'output_filename': item['output_image']\n","        }\n","\n","    def get_color_embedding_dim(self):\n","        \"\"\"Return the dimension of color embeddings (number of unique colors)\"\"\"\n","        return self.num_colors\n","\n","\n","def get_data_loaders(train_json_path: str,\n","                    val_json_path: str,\n","                    train_input_dir: str,\n","                    train_output_dir: str,\n","                    val_input_dir: str,\n","                    val_output_dir: str,\n","                    batch_size: int = 16,\n","                    image_size: int = 256,\n","                    num_workers: int = 4,\n","                    use_augmentations: bool = True):\n","\n","    # Define augmentations for training\n","    train_augmentations = None\n","    if use_augmentations:\n","        train_augmentations = transforms.Compose([\n","            transforms.RandomHorizontalFlip(p=0.5),\n","            transforms.RandomRotation(degrees=15),\n","            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n","        ])\n","\n","    # Create datasets\n","    train_dataset = PolygonColorDataset(\n","        data_json_path=train_json_path,\n","        input_dir=train_input_dir,\n","        output_dir=train_output_dir,\n","        image_size=image_size,\n","        augmentations=train_augmentations\n","    )\n","\n","    # Use the color mapping from the training set for the validation set\n","    color_to_idx = train_dataset.color_to_idx\n","\n","    val_dataset = PolygonColorDataset(\n","        data_json_path=val_json_path,\n","        input_dir=val_input_dir,\n","        output_dir=val_output_dir,\n","        image_size=image_size,\n","        augmentations=None,  # No augmentations for validation\n","        color_to_idx=color_to_idx\n","    )\n","\n","    # Create data loaders\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=num_workers,\n","        pin_memory=True,\n","        drop_last=True\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=num_workers,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","\n","    # Return color information for model initialization\n","    color_info = {\n","        'colors': train_dataset.colors,\n","        'color_to_idx': train_dataset.color_to_idx,\n","        'num_colors': train_dataset.num_colors\n","    }\n","\n","    return train_loader, val_loader, color_info\n","\n","\n","# Example usage and testing\n","if __name__ == \"__main__\":\n","    # Test dataset loading\n","    dataset = PolygonColorDataset(\n","        data_json_path=\"/content/drive/MyDrive/dataset/dataset/training/data.json\",\n","        input_dir=\"/content/drive/MyDrive/dataset/dataset/training/inputs\",\n","        output_dir=\"/content/drive/MyDrive/dataset/dataset/training/outputs\",\n","        image_size=256\n","    )\n","\n","    # Test a single sample\n","    sample = dataset[0]\n","    print(f\"Sample keys: {sample.keys()}\")\n","    print(f\"Input image shape: {sample['input_image'].shape}\")\n","    print(f\"Output image shape: {sample['output_image'].shape}\")\n","    print(f\"Color onehot shape: {sample['color_onehot'].shape}\")\n","    print(f\"Color name: {sample['color_name']}\")\n","    print(f\"Color index: {sample['color_idx']}\")\n","\n","    # Test data loader\n","    from torch.utils.data import DataLoader\n","    loader = DataLoader(dataset, batch_size=4, shuffle=True)\n","    batch = next(iter(loader))\n","    print(f\"\\nBatch input shape: {batch['input_image'].shape}\")\n","    print(f\"Batch output shape: {batch['output_image'].shape}\")\n","    print(f\"Batch color onehot shape: {batch['color_onehot'].shape}\")"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from typing import Optional\n","\n","\n","class DoubleConv(nn.Module):\n","    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n","\n","    def __init__(self, in_channels: int, out_channels: int, mid_channels: Optional[int] = None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","\n","class Down(nn.Module):\n","    \"\"\"Downscaling with maxpool then double conv\"\"\"\n","\n","    def __init__(self, in_channels: int, out_channels: int):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","\n","class Up(nn.Module):\n","    \"\"\"Upscaling then double conv\"\"\"\n","\n","    def __init__(self, in_channels: int, out_channels: int, bilinear: bool = True):\n","        super().__init__()\n","\n","        # if bilinear, use the normal convolutions to reduce the number of channels\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        # input is CHW\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        # if you have padding issues, see\n","        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n","        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels: int, out_channels: int):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","\n","class FiLM(nn.Module):\n","    \"\"\"Feature-wise Linear Modulation layer\"\"\"\n","\n","    def __init__(self, condition_dim: int, feature_dim: int):\n","        super().__init__()\n","        self.condition_dim = condition_dim\n","        self.feature_dim = feature_dim\n","\n","        # Linear layers to generate scale (gamma) and shift (beta) parameters\n","        self.gamma_linear = nn.Linear(condition_dim, feature_dim)\n","        self.beta_linear = nn.Linear(condition_dim, feature_dim)\n","\n","    def forward(self, x, condition):\n","        \"\"\"\n","        Args:\n","            x: Feature tensor of shape (B, C, H, W)\n","            condition: Condition tensor of shape (B, condition_dim)\n","\n","        Returns:\n","            Modulated features of shape (B, C, H, W)\n","        \"\"\"\n","        # Generate scale and shift parameters\n","        gamma = self.gamma_linear(condition)  # (B, feature_dim)\n","        beta = self.beta_linear(condition)    # (B, feature_dim)\n","\n","        # Reshape for broadcasting with feature maps\n","        gamma = gamma.view(gamma.size(0), gamma.size(1), 1, 1)  # (B, C, 1, 1)\n","        beta = beta.view(beta.size(0), beta.size(1), 1, 1)      # (B, C, 1, 1)\n","\n","        # Apply FiLM: scale and shift\n","        return gamma * x + beta\n","\n","\n","class ConditionalUNet(nn.Module):\n","    \"\"\"\n","    Conditional UNet for polygon coloring.\n","    Takes an input image and color condition to generate colored polygon.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 n_channels: int = 3,\n","                 n_classes: int = 3,\n","                 num_colors: int = 8,\n","                 color_embed_dim: int = 128,\n","                 bilinear: bool = True):\n","        super(ConditionalUNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.num_colors = num_colors\n","        self.color_embed_dim = color_embed_dim\n","        self.bilinear = bilinear\n","\n","        # Color embedding layer\n","        self.color_embedding = nn.Sequential(\n","            nn.Linear(num_colors, color_embed_dim),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(color_embed_dim, color_embed_dim),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        # UNet encoder\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Down(512, 1024 // factor)\n","\n","        # FiLM layers for conditioning at different scales\n","        self.film1 = FiLM(color_embed_dim, 64)\n","        self.film2 = FiLM(color_embed_dim, 128)\n","        self.film3 = FiLM(color_embed_dim, 256)\n","        self.film4 = FiLM(color_embed_dim, 512)\n","        self.film5 = FiLM(color_embed_dim, 1024 // factor)\n","\n","        # UNet decoder\n","        self.up1 = Up(1024, 512 // factor, bilinear)\n","        self.up2 = Up(512, 256 // factor, bilinear)\n","        self.up3 = Up(256, 128 // factor, bilinear)\n","        self.up4 = Up(128, 64, bilinear)\n","        self.outc = OutConv(64, n_classes)\n","\n","        # Output activation\n","        self.output_activation = nn.Tanh()  # Output in [-1, 1] range\n","\n","    def forward(self, x, color_condition):\n","        \"\"\"\n","        Args:\n","            x: Input image tensor of shape (B, 3, H, W)\n","            color_condition: Color condition tensor of shape (B, num_colors) - one-hot encoded\n","\n","        Returns:\n","            Generated colored polygon of shape (B, 3, H, W)\n","        \"\"\"\n","        # Embed color condition\n","        color_embed = self.color_embedding(color_condition)  # (B, color_embed_dim)\n","\n","        # Encoder path with FiLM conditioning\n","        x1 = self.inc(x)\n","        x1 = self.film1(x1, color_embed)\n","\n","        x2 = self.down1(x1)\n","        x2 = self.film2(x2, color_embed)\n","\n","        x3 = self.down2(x2)\n","        x3 = self.film3(x3, color_embed)\n","\n","        x4 = self.down3(x3)\n","        x4 = self.film4(x4, color_embed)\n","\n","        x5 = self.down4(x4)\n","        x5 = self.film5(x5, color_embed)\n","\n","        # Decoder path\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","\n","        # Output layer\n","        logits = self.outc(x)\n","        output = self.output_activation(logits)\n","\n","        return output\n","\n","\n","class AlternativeConditionalUNet(nn.Module):\n","    def __init__(self,\n","                 n_channels: int = 3,\n","                 n_classes: int = 3,\n","                 num_colors: int = 8,\n","                 bilinear: bool = True):\n","        super(AlternativeConditionalUNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.num_colors = num_colors\n","        self.bilinear = bilinear\n","\n","        # Input channels = image channels + color channels\n","        input_channels = n_channels + num_colors\n","\n","        # UNet architecture\n","        self.inc = DoubleConv(input_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Down(512, 1024 // factor)\n","\n","        self.up1 = Up(1024, 512 // factor, bilinear)\n","        self.up2 = Up(512, 256 // factor, bilinear)\n","        self.up3 = Up(256, 128 // factor, bilinear)\n","        self.up4 = Up(128, 64, bilinear)\n","        self.outc = OutConv(64, n_classes)\n","\n","        self.output_activation = nn.Tanh()\n","\n","    def forward(self, x, color_condition):\n","        \"\"\"\n","        Args:\n","            x: Input image tensor of shape (B, 3, H, W)\n","            color_condition: Color condition tensor of shape (B, num_colors)\n","\n","        Returns:\n","            Generated colored polygon of shape (B, 3, H, W)\n","        \"\"\"\n","        batch_size, _, height, width = x.shape\n","\n","        # Expand color condition to match spatial dimensions\n","        color_maps = color_condition.unsqueeze(-1).unsqueeze(-1)  # (B, num_colors, 1, 1)\n","        color_maps = color_maps.expand(-1, -1, height, width)     # (B, num_colors, H, W)\n","\n","        # Concatenate image and color information\n","        x_conditioned = torch.cat([x, color_maps], dim=1)  # (B, 3+num_colors, H, W)\n","\n","        # Standard UNet forward pass\n","        x1 = self.inc(x_conditioned)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","\n","        logits = self.outc(x)\n","        output = self.output_activation(logits)\n","\n","        return output\n","\n","\n","def create_model(model_type: str = \"film\", **kwargs):\n","    if model_type == \"film\":\n","        return ConditionalUNet(**kwargs)\n","    elif model_type == \"concat\":\n","        return AlternativeConditionalUNet(**kwargs)\n","    else:\n","        raise ValueError(f\"Unknown model type: {model_type}\")\n","\n","\n","# Test the models\n","if __name__ == \"__main__\":\n","    # Test FiLM-based model\n","    model_film = ConditionalUNet(num_colors=8)\n","\n","    # Test input\n","    batch_size = 2\n","    x = torch.randn(batch_size, 3, 256, 256)\n","    color_condition = torch.zeros(batch_size, 8)\n","    color_condition[0, 0] = 1  # First sample: color 0\n","    color_condition[1, 3] = 1  # Second sample: color 3\n","\n","    # Forward pass\n","    output = model_film(x, color_condition)\n","    print(f\"FiLM model output shape: {output.shape}\")\n","\n","    # Test concatenation-based model\n","    model_concat = AlternativeConditionalUNet(num_colors=8)\n","    output_concat = model_concat(x, color_condition)\n","    print(f\"Concatenation model output shape: {output_concat.shape}\")\n","\n","    # Count parameters\n","    def count_parameters(model):\n","        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    print(f\"FiLM model parameters: {count_parameters(model_film):,}\")\n","    print(f\"Concatenation model parameters: {count_parameters(model_concat):,}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4CFtH3EelQw","executionInfo":{"status":"ok","timestamp":1754293691523,"user_tz":-330,"elapsed":6662,"user":{"displayName":"Megha Shyam","userId":"08441739143667292717"}},"outputId":"10eaaf9d-3c97-4074-c099-68c9cbdf85e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FiLM model output shape: torch.Size([2, 3, 256, 256])\n","Concatenation model output shape: torch.Size([2, 3, 256, 256])\n","FiLM model parameters: 17,660,547\n","Concatenation model parameters: 17,267,715\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import wandb\n","import os\n","import time\n","from datetime import datetime\n","import numpy as np\n","from PIL import Image\n","import torchvision.transforms as transforms\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","\n","class PolygonColoringTrainer:\n","    \"\"\"\n","    Trainer class for the polygon coloring task using conditional UNet.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 config: dict,\n","                 train_loader: DataLoader,\n","                 val_loader: DataLoader,\n","                 color_info: dict):\n","\n","        self.config = config\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.color_info = color_info\n","\n","        # Setup device\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        print(f\"Using device: {self.device}\")\n","\n","        # Initialize model\n","        self.model = create_model(\n","            model_type=config['model_type'],\n","            num_colors=color_info['num_colors'],\n","            n_channels=config['n_channels'],\n","            n_classes=config['n_classes'],\n","            color_embed_dim=config.get('color_embed_dim', 128),\n","            bilinear=config.get('bilinear', True)\n","        ).to(self.device)\n","\n","        # Count parameters\n","        num_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n","        print(f\"Model has {num_params:,} trainable parameters\")\n","\n","        # Initialize optimizer\n","        if config['optimizer'] == 'adam':\n","            self.optimizer = optim.Adam(\n","                self.model.parameters(),\n","                lr=config['learning_rate'],\n","                weight_decay=config.get('weight_decay', 1e-4)\n","            )\n","        elif config['optimizer'] == 'adamw':\n","            self.optimizer = optim.AdamW(\n","                self.model.parameters(),\n","                lr=config['learning_rate'],\n","                weight_decay=config.get('weight_decay', 1e-2)\n","            )\n","        else:\n","            raise ValueError(f\"Unsupported optimizer: {config['optimizer']}\")\n","\n","        # Initialize scheduler\n","        if config.get('scheduler') == 'cosine':\n","            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n","                self.optimizer,\n","                T_max=config['epochs'],\n","                eta_min=config['learning_rate'] * 0.01\n","            )\n","        elif config.get('scheduler') == 'step':\n","            self.scheduler = optim.lr_scheduler.StepLR(\n","                self.optimizer,\n","                step_size=config.get('step_size', 50),\n","                gamma=config.get('gamma', 0.5)\n","            )\n","        else:\n","            self.scheduler = None\n","\n","        # Initialize loss function\n","        if config['loss_function'] == 'mse':\n","            self.criterion = nn.MSELoss()\n","        elif config['loss_function'] == 'l1':\n","            self.criterion = nn.L1Loss()\n","        elif config['loss_function'] == 'huber':\n","            self.criterion = nn.SmoothL1Loss()\n","        else:\n","            raise ValueError(f\"Unsupported loss function: {config['loss_function']}\")\n","\n","        # Training state\n","        self.current_epoch = 0\n","        self.best_val_loss = float('inf')\n","        self.train_losses = []\n","        self.val_losses = []\n","\n","        # Create output directories\n","        os.makedirs(config['checkpoint_dir'], exist_ok=True)\n","        os.makedirs(config['sample_dir'], exist_ok=True)\n","\n","    def train_epoch(self):\n","        self.model.train()\n","        epoch_loss = 0.0\n","        num_batches = len(self.train_loader)\n","\n","        pbar = tqdm(self.train_loader, desc=f'Epoch {self.current_epoch + 1}/{self.config[\"epochs\"]}')\n","\n","        for batch_idx, batch in enumerate(pbar):\n","            # Move data to device\n","            input_images = batch['input_image'].to(self.device)\n","            color_conditions = batch['color_onehot'].to(self.device)\n","            target_images = batch['output_image'].to(self.device)\n","\n","            # Forward pass\n","            self.optimizer.zero_grad()\n","            predicted_images = self.model(input_images, color_conditions)\n","\n","            # Compute loss\n","            loss = self.criterion(predicted_images, target_images)\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Gradient clipping (optional)\n","            if self.config.get('grad_clip'):\n","                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config['grad_clip'])\n","\n","            self.optimizer.step()\n","\n","            # Update metrics\n","            epoch_loss += loss.item()\n","\n","            # Update progress bar\n","            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n","\n","            # Log to wandb\n","            if batch_idx % self.config.get('log_interval', 50) == 0:\n","                wandb.log({\n","                    'train_loss_step': loss.item(),\n","                    'learning_rate': self.optimizer.param_groups[0]['lr'],\n","                    'epoch': self.current_epoch,\n","                    'step': self.current_epoch * num_batches + batch_idx\n","                })\n","\n","        avg_epoch_loss = epoch_loss / num_batches\n","        self.train_losses.append(avg_epoch_loss)\n","\n","        return avg_epoch_loss\n","\n","    def validate_epoch(self):\n","        self.model.eval()\n","        epoch_loss = 0.0\n","        num_batches = len(self.val_loader)\n","\n","        # Store samples for visualization\n","        sample_inputs = []\n","        sample_predictions = []\n","        sample_targets = []\n","        sample_colors = []\n","\n","        with torch.no_grad():\n","            for batch_idx, batch in enumerate(tqdm(self.val_loader, desc='Validating')):\n","                # Move data to device\n","                input_images = batch['input_image'].to(self.device)\n","                color_conditions = batch['color_onehot'].to(self.device)\n","                target_images = batch['output_image'].to(self.device)\n","\n","                # Forward pass\n","                predicted_images = self.model(input_images, color_conditions)\n","\n","                # Compute loss\n","                loss = self.criterion(predicted_images, target_images)\n","                epoch_loss += loss.item()\n","\n","                # Store first batch samples for visualization\n","                if batch_idx == 0:\n","                    sample_inputs = input_images[:4].cpu()\n","                    sample_predictions = predicted_images[:4].cpu()\n","                    sample_targets = target_images[:4].cpu()\n","                    sample_colors = [batch['color_name'][i] for i in range(min(4, len(batch['color_name'])))]\n","\n","        avg_epoch_loss = epoch_loss / num_batches\n","        self.val_losses.append(avg_epoch_loss)\n","\n","        # Create and log sample images\n","        if len(sample_inputs) > 0:\n","            self.log_sample_images(\n","                sample_inputs, sample_predictions, sample_targets, sample_colors\n","            )\n","\n","        return avg_epoch_loss\n","\n","    def log_sample_images(self, inputs, predictions, targets, colors):\n","        # Denormalize images from [-1, 1] to [0, 1]\n","        def denormalize(tensor):\n","            return (tensor + 1) / 2\n","\n","        inputs = denormalize(inputs)\n","        predictions = denormalize(predictions)\n","        targets = denormalize(targets)\n","\n","        # Create comparison grid\n","        fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n","\n","        for i in range(4):\n","            # Input image\n","            axes[0, i].imshow(inputs[i].permute(1, 2, 0))\n","            axes[0, i].set_title(f'Input ({colors[i]})')\n","            axes[0, i].axis('off')\n","\n","            # Predicted image\n","            axes[1, i].imshow(predictions[i].permute(1, 2, 0))\n","            axes[1, i].set_title('Predicted')\n","            axes[1, i].axis('off')\n","\n","            # Target image\n","            axes[2, i].imshow(targets[i].permute(1, 2, 0))\n","            axes[2, i].set_title('Target')\n","            axes[2, i].axis('off')\n","\n","        plt.tight_layout()\n","\n","        # Log to wandb\n","        wandb.log({\n","            'sample_images': wandb.Image(fig),\n","            'epoch': self.current_epoch\n","        })\n","\n","        plt.close(fig)\n","\n","        # Save sample images to disk\n","        sample_path = os.path.join(\n","            self.config['sample_dir'],\n","            f'epoch_{self.current_epoch:03d}.png'\n","        )\n","\n","        # Create a single image with all samples\n","        grid_img = torch.cat([\n","            torch.cat([inputs[i] for i in range(4)], dim=2),\n","            torch.cat([predictions[i] for i in range(4)], dim=2),\n","            torch.cat([targets[i] for i in range(4)], dim=2)\n","        ], dim=1)\n","\n","        transforms.ToPILImage()(grid_img).save(sample_path)\n","\n","    def save_checkpoint(self, is_best=False):\n","        checkpoint = {\n","            'epoch': self.current_epoch,\n","            'model_state_dict': self.model.state_dict(),\n","            'optimizer_state_dict': self.optimizer.state_dict(),\n","            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\n","            'train_losses': self.train_losses,\n","            'val_losses': self.val_losses,\n","            'best_val_loss': self.best_val_loss,\n","            'config': self.config,\n","            'color_info': self.color_info\n","        }\n","\n","        # Save latest checkpoint\n","        latest_path = os.path.join(self.config['checkpoint_dir'], 'latest_checkpoint.pth')\n","        torch.save(checkpoint, latest_path)\n","\n","        # Save best checkpoint\n","        if is_best:\n","            best_path = os.path.join(self.config['checkpoint_dir'], 'best_checkpoint.pth')\n","            torch.save(checkpoint, best_path)\n","            print(f\"New best model saved with validation loss: {self.best_val_loss:.4f}\")\n","\n","    def load_checkpoint(self, checkpoint_path):\n","        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n","\n","        self.model.load_state_dict(checkpoint['model_state_dict'])\n","        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","        if self.scheduler and checkpoint['scheduler_state_dict']:\n","            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","\n","        self.current_epoch = checkpoint['epoch']\n","        self.train_losses = checkpoint['train_losses']\n","        self.val_losses = checkpoint['val_losses']\n","        self.best_val_loss = checkpoint['best_val_loss']\n","\n","        print(f\"Loaded checkpoint from epoch {self.current_epoch}\")\n","\n","    def train(self):\n","        print(\"Starting training...\")\n","        start_time = time.time()\n","\n","        for epoch in range(self.current_epoch, self.config['epochs']):\n","            self.current_epoch = epoch\n","\n","            # Train\n","            train_loss = self.train_epoch()\n","\n","            # Validate\n","            val_loss = self.validate_epoch()\n","\n","            # Update scheduler\n","            if self.scheduler:\n","                self.scheduler.step()\n","\n","            # Log epoch metrics\n","            wandb.log({\n","                'epoch': epoch,\n","                'train_loss_epoch': train_loss,\n","                'val_loss_epoch': val_loss,\n","                'learning_rate': self.optimizer.param_groups[0]['lr']\n","            })\n","\n","            # Save checkpoint\n","            is_best = val_loss < self.best_val_loss\n","            if is_best:\n","                self.best_val_loss = val_loss\n","\n","            if epoch % self.config.get('save_interval', 10) == 0 or is_best:\n","                self.save_checkpoint(is_best=is_best)\n","\n","            # Print epoch summary\n","            elapsed_time = time.time() - start_time\n","            print(f\"Epoch {epoch + 1}/{self.config['epochs']} - \"\n","                  f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n","                  f\"Time: {elapsed_time/60:.1f}min\")\n","\n","        print(f\"Training completed! Best validation loss: {self.best_val_loss:.4f}\")\n","\n","\n","def main():\n","    # Training configuration\n","    config = {\n","        # Model configuration\n","        'model_type': 'film',  # 'film' or 'concat'\n","        'n_channels': 3,\n","        'n_classes': 3,\n","        'color_embed_dim': 128,\n","        'bilinear': True,\n","\n","        # Training configuration\n","        'epochs': 100,\n","        'batch_size': 16,\n","        'learning_rate': 1e-3,\n","        'optimizer': 'adamw',\n","        'weight_decay': 1e-2,\n","        'scheduler': 'cosine',\n","        'loss_function': 'l1',  # 'mse', 'l1', 'huber'\n","        'grad_clip': 1.0,\n","\n","        # Data configuration\n","        'image_size': 256,\n","        'num_workers': 4,\n","        'use_augmentations': True,\n","\n","        # Logging and saving\n","        'log_interval': 20,\n","        'save_interval': 10,\n","        'checkpoint_dir': 'checkpoints',\n","        'sample_dir': 'samples',\n","\n","        # Paths\n","        'train_json': '/content/drive/MyDrive/dataset/dataset/training/data.json',\n","        'val_json': '/content/drive/MyDrive/dataset/dataset/validation/data.json',\n","        'train_input_dir': '/content/drive/MyDrive/dataset/dataset/training/inputs',\n","        'train_output_dir': '/content/drive/MyDrive/dataset/dataset/training/outputs',\n","        'val_input_dir': '/content/drive/MyDrive/dataset/dataset/validation/inputs',\n","        'val_output_dir': '/content/drive/MyDrive/dataset/dataset/validation/outputs',\n","    }\n","\n","    # Initialize wandb\n","    wandb.init(\n","        project=\"polygon-coloring\",\n","        config=config,\n","        name=f\"unet-{config['model_type']}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n","    )\n","\n","\n","    # Create data loaders\n","    train_loader, val_loader, color_info = get_data_loaders(\n","        train_json_path=config['train_json'],\n","        val_json_path=config['val_json'],\n","        train_input_dir=config['train_input_dir'],\n","        train_output_dir=config['train_output_dir'],\n","        val_input_dir=config['val_input_dir'],\n","        val_output_dir=config['val_output_dir'],\n","        batch_size=config['batch_size'],\n","        image_size=config['image_size'],\n","        num_workers=config['num_workers'],\n","        use_augmentations=config['use_augmentations']\n","    )\n","\n","    # Initialize trainer\n","    trainer = PolygonColoringTrainer(config, train_loader, val_loader, color_info)\n","\n","    # Start training\n","    trainer.train()\n","\n","    # Finish wandb run\n","    wandb.finish()\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xjTltVzifqk1","executionInfo":{"status":"ok","timestamp":1754294413101,"user_tz":-330,"elapsed":721576,"user":{"displayName":"Megha Shyam","userId":"08441739143667292717"}},"outputId":"ca822e93-563a-4bf2-f3a6-5faf15b4c340"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmeghashyam2005\u001b[0m (\u001b[33mmeghashyam2005-mahindra-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250804_074855-uhdhzwbw</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring/runs/uhdhzwbw' target=\"_blank\">unet-film-20250804-074813</a></strong> to <a href='https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring' target=\"_blank\">https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring/runs/uhdhzwbw' target=\"_blank\">https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring/runs/uhdhzwbw</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset initialized with 56 samples\n","Colors: ['blue', 'cyan', 'green', 'magenta', 'orange', 'purple', 'red', 'yellow']\n","Color mapping: {'blue': 0, 'cyan': 1, 'green': 2, 'magenta': 3, 'orange': 4, 'purple': 5, 'red': 6, 'yellow': 7}\n","Dataset initialized with 5 samples\n","Colors: ['blue', 'cyan', 'green', 'magenta', 'orange', 'purple', 'red', 'yellow']\n","Color mapping: {'blue': 0, 'cyan': 1, 'green': 2, 'magenta': 3, 'orange': 4, 'purple': 5, 'red': 6, 'yellow': 7}\n","Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model has 17,660,547 trainable parameters\n","Starting training...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/100: 100%|██████████| 3/3 [00:10<00:00,  3.64s/it, Loss=0.8191]\n","Validating: 100%|██████████| 1/1 [00:04<00:00,  4.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.9958\n","Epoch 1/100 - Train Loss: 0.8564, Val Loss: 0.9958, Time: 0.3min\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 2/100:   0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Epoch 2/100: 100%|██████████| 3/3 [00:04<00:00,  1.48s/it, Loss=0.6776]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100 - Train Loss: 0.7231, Val Loss: 1.0316, Time: 0.4min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/100: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, Loss=0.5448]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/100 - Train Loss: 0.5816, Val Loss: 1.1396, Time: 0.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/100: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it, Loss=0.5156]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/100 - Train Loss: 0.5328, Val Loss: 1.2906, Time: 0.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/100: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it, Loss=0.4707]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/100 - Train Loss: 0.4763, Val Loss: 1.2523, Time: 0.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/100: 100%|██████████| 3/3 [00:04<00:00,  1.65s/it, Loss=0.4154]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/100 - Train Loss: 0.4361, Val Loss: 1.1791, Time: 0.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/100: 100%|██████████| 3/3 [00:03<00:00,  1.29s/it, Loss=0.3871]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/100 - Train Loss: 0.3859, Val Loss: 1.1260, Time: 0.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/100: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it, Loss=0.3619]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.8148\n","Epoch 8/100 - Train Loss: 0.3587, Val Loss: 0.8148, Time: 1.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/100: 100%|██████████| 3/3 [00:03<00:00,  1.31s/it, Loss=0.3019]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.7222\n","Epoch 9/100 - Train Loss: 0.3136, Val Loss: 0.7222, Time: 1.1min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/100: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it, Loss=0.2791]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.5992\n","Epoch 10/100 - Train Loss: 0.2878, Val Loss: 0.5992, Time: 1.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/100: 100%|██████████| 3/3 [00:04<00:00,  1.59s/it, Loss=0.2652]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.4712\n","Epoch 11/100 - Train Loss: 0.2852, Val Loss: 0.4712, Time: 1.4min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/100: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it, Loss=0.2525]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.2933\n","Epoch 12/100 - Train Loss: 0.2563, Val Loss: 0.2933, Time: 1.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/100: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it, Loss=0.2156]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.2418\n","Epoch 13/100 - Train Loss: 0.2295, Val Loss: 0.2418, Time: 1.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/100: 100%|██████████| 3/3 [00:04<00:00,  1.45s/it, Loss=0.2188]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/100 - Train Loss: 0.2197, Val Loss: 0.2521, Time: 1.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/100: 100%|██████████| 3/3 [00:03<00:00,  1.27s/it, Loss=0.1845]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.2379\n","Epoch 15/100 - Train Loss: 0.1909, Val Loss: 0.2379, Time: 1.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/100: 100%|██████████| 3/3 [00:03<00:00,  1.31s/it, Loss=0.1767]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/100 - Train Loss: 0.1929, Val Loss: 0.2413, Time: 1.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/100: 100%|██████████| 3/3 [00:04<00:00,  1.52s/it, Loss=0.1657]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/100 - Train Loss: 0.1684, Val Loss: 0.2458, Time: 2.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/100: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it, Loss=0.1826]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.2221\n","Epoch 18/100 - Train Loss: 0.1634, Val Loss: 0.2221, Time: 2.2min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/100: 100%|██████████| 3/3 [00:05<00:00,  1.76s/it, Loss=0.1626]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1914\n","Epoch 19/100 - Train Loss: 0.1533, Val Loss: 0.1914, Time: 2.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/100: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it, Loss=0.1368]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1726\n","Epoch 20/100 - Train Loss: 0.1482, Val Loss: 0.1726, Time: 2.4min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21/100: 100%|██████████| 3/3 [00:04<00:00,  1.49s/it, Loss=0.1310]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1602\n","Epoch 21/100 - Train Loss: 0.1356, Val Loss: 0.1602, Time: 2.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 22/100: 100%|██████████| 3/3 [00:04<00:00,  1.34s/it, Loss=0.1501]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1568\n","Epoch 22/100 - Train Loss: 0.1379, Val Loss: 0.1568, Time: 2.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 23/100: 100%|██████████| 3/3 [00:04<00:00,  1.60s/it, Loss=0.1415]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23/100 - Train Loss: 0.1503, Val Loss: 0.1594, Time: 2.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 24/100: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it, Loss=0.1441]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24/100 - Train Loss: 0.1427, Val Loss: 0.1622, Time: 2.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 25/100: 100%|██████████| 3/3 [00:05<00:00,  1.77s/it, Loss=0.1302]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25/100 - Train Loss: 0.1426, Val Loss: 0.1620, Time: 3.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 26/100: 100%|██████████| 3/3 [00:03<00:00,  1.31s/it, Loss=0.1378]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26/100 - Train Loss: 0.1329, Val Loss: 0.1620, Time: 3.1min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 27/100: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it, Loss=0.1339]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1559\n","Epoch 27/100 - Train Loss: 0.1374, Val Loss: 0.1559, Time: 3.2min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 28/100: 100%|██████████| 3/3 [00:03<00:00,  1.33s/it, Loss=0.1266]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1488\n","Epoch 28/100 - Train Loss: 0.1370, Val Loss: 0.1488, Time: 3.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 29/100: 100%|██████████| 3/3 [00:05<00:00,  1.71s/it, Loss=0.1402]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1440\n","Epoch 29/100 - Train Loss: 0.1337, Val Loss: 0.1440, Time: 3.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 30/100: 100%|██████████| 3/3 [00:04<00:00,  1.45s/it, Loss=0.1092]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1411\n","Epoch 30/100 - Train Loss: 0.1170, Val Loss: 0.1411, Time: 3.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 31/100: 100%|██████████| 3/3 [00:04<00:00,  1.49s/it, Loss=0.1049]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31/100 - Train Loss: 0.1239, Val Loss: 0.1440, Time: 3.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 32/100: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, Loss=0.1100]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32/100 - Train Loss: 0.1192, Val Loss: 0.1438, Time: 3.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 33/100: 100%|██████████| 3/3 [00:05<00:00,  1.79s/it, Loss=0.1356]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1397\n","Epoch 33/100 - Train Loss: 0.1240, Val Loss: 0.1397, Time: 3.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 34/100: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, Loss=0.1287]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34/100 - Train Loss: 0.1256, Val Loss: 0.1423, Time: 4.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 35/100: 100%|██████████| 3/3 [00:04<00:00,  1.63s/it, Loss=0.1200]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35/100 - Train Loss: 0.1266, Val Loss: 0.1411, Time: 4.1min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 36/100: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it, Loss=0.0991]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1379\n","Epoch 36/100 - Train Loss: 0.1205, Val Loss: 0.1379, Time: 4.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 37/100: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, Loss=0.1270]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1347\n","Epoch 37/100 - Train Loss: 0.1148, Val Loss: 0.1347, Time: 4.4min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 38/100: 100%|██████████| 3/3 [00:04<00:00,  1.44s/it, Loss=0.1167]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1338\n","Epoch 38/100 - Train Loss: 0.1163, Val Loss: 0.1338, Time: 4.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 39/100: 100%|██████████| 3/3 [00:04<00:00,  1.54s/it, Loss=0.1158]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39/100 - Train Loss: 0.1191, Val Loss: 0.1366, Time: 4.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 40/100: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it, Loss=0.1225]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40/100 - Train Loss: 0.1198, Val Loss: 0.1391, Time: 4.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 41/100: 100%|██████████| 3/3 [00:04<00:00,  1.50s/it, Loss=0.1232]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41/100 - Train Loss: 0.1152, Val Loss: 0.1387, Time: 4.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 42/100: 100%|██████████| 3/3 [00:04<00:00,  1.51s/it, Loss=0.1033]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42/100 - Train Loss: 0.1155, Val Loss: 0.1365, Time: 4.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 43/100: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it, Loss=0.0994]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1330\n","Epoch 43/100 - Train Loss: 0.1110, Val Loss: 0.1330, Time: 5.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 44/100: 100%|██████████| 3/3 [00:05<00:00,  1.75s/it, Loss=0.0980]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1312\n","Epoch 44/100 - Train Loss: 0.1080, Val Loss: 0.1312, Time: 5.2min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 45/100: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it, Loss=0.1131]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45/100 - Train Loss: 0.1095, Val Loss: 0.1317, Time: 5.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 46/100: 100%|██████████| 3/3 [00:04<00:00,  1.62s/it, Loss=0.1083]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46/100 - Train Loss: 0.1030, Val Loss: 0.1416, Time: 5.4min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 47/100: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it, Loss=0.1019]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47/100 - Train Loss: 0.1027, Val Loss: 0.1369, Time: 5.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 48/100: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it, Loss=0.1101]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1283\n","Epoch 48/100 - Train Loss: 0.1065, Val Loss: 0.1283, Time: 5.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 49/100: 100%|██████████| 3/3 [00:04<00:00,  1.34s/it, Loss=0.1031]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49/100 - Train Loss: 0.0990, Val Loss: 0.1310, Time: 5.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 50/100: 100%|██████████| 3/3 [00:04<00:00,  1.65s/it, Loss=0.0983]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1275\n","Epoch 50/100 - Train Loss: 0.0945, Val Loss: 0.1275, Time: 5.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 51/100: 100%|██████████| 3/3 [00:03<00:00,  1.33s/it, Loss=0.0936]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51/100 - Train Loss: 0.1021, Val Loss: 0.1533, Time: 6.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 52/100: 100%|██████████| 3/3 [00:04<00:00,  1.57s/it, Loss=0.0997]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52/100 - Train Loss: 0.0991, Val Loss: 0.1363, Time: 6.1min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 53/100: 100%|██████████| 3/3 [00:04<00:00,  1.39s/it, Loss=0.0809]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53/100 - Train Loss: 0.0904, Val Loss: 0.1331, Time: 6.2min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 54/100: 100%|██████████| 3/3 [00:04<00:00,  1.34s/it, Loss=0.0679]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54/100 - Train Loss: 0.0907, Val Loss: 0.1369, Time: 6.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 55/100: 100%|██████████| 3/3 [00:04<00:00,  1.63s/it, Loss=0.0767]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55/100 - Train Loss: 0.0893, Val Loss: 0.1286, Time: 6.4min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 56/100: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, Loss=0.0794]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1245\n","Epoch 56/100 - Train Loss: 0.0824, Val Loss: 0.1245, Time: 6.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 57/100: 100%|██████████| 3/3 [00:05<00:00,  1.69s/it, Loss=0.0894]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1187\n","Epoch 57/100 - Train Loss: 0.0834, Val Loss: 0.1187, Time: 6.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 58/100: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it, Loss=0.0768]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58/100 - Train Loss: 0.0789, Val Loss: 0.1337, Time: 6.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 59/100: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it, Loss=0.0856]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59/100 - Train Loss: 0.0792, Val Loss: 0.1402, Time: 6.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 60/100: 100%|██████████| 3/3 [00:04<00:00,  1.39s/it, Loss=0.0751]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60/100 - Train Loss: 0.0713, Val Loss: 0.1381, Time: 6.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 61/100: 100%|██████████| 3/3 [00:04<00:00,  1.62s/it, Loss=0.0865]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61/100 - Train Loss: 0.0721, Val Loss: 0.1309, Time: 7.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 62/100: 100%|██████████| 3/3 [00:04<00:00,  1.52s/it, Loss=0.0674]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62/100 - Train Loss: 0.0720, Val Loss: 0.1466, Time: 7.1min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 63/100: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it, Loss=0.0566]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63/100 - Train Loss: 0.0664, Val Loss: 0.1387, Time: 7.2min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 64/100: 100%|██████████| 3/3 [00:04<00:00,  1.47s/it, Loss=0.0763]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64/100 - Train Loss: 0.0707, Val Loss: 0.1397, Time: 7.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 65/100: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it, Loss=0.0573]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65/100 - Train Loss: 0.0634, Val Loss: 0.1468, Time: 7.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 66/100: 100%|██████████| 3/3 [00:05<00:00,  1.69s/it, Loss=0.0666]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66/100 - Train Loss: 0.0635, Val Loss: 0.1284, Time: 7.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 67/100: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it, Loss=0.0711]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67/100 - Train Loss: 0.0658, Val Loss: 0.1251, Time: 7.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 68/100: 100%|██████████| 3/3 [00:05<00:00,  1.78s/it, Loss=0.0558]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1158\n","Epoch 68/100 - Train Loss: 0.0633, Val Loss: 0.1158, Time: 7.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 69/100: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it, Loss=0.0648]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1130\n","Epoch 69/100 - Train Loss: 0.0621, Val Loss: 0.1130, Time: 7.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 70/100: 100%|██████████| 3/3 [00:04<00:00,  1.65s/it, Loss=0.0498]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70/100 - Train Loss: 0.0547, Val Loss: 0.1152, Time: 8.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 71/100: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it, Loss=0.0581]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation loss: 0.1094\n","Epoch 71/100 - Train Loss: 0.0629, Val Loss: 0.1094, Time: 8.2min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 72/100: 100%|██████████| 3/3 [00:05<00:00,  1.76s/it, Loss=0.0525]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72/100 - Train Loss: 0.0557, Val Loss: 0.1100, Time: 8.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 73/100: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it, Loss=0.0549]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73/100 - Train Loss: 0.0562, Val Loss: 0.1163, Time: 8.4min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 74/100: 100%|██████████| 3/3 [00:05<00:00,  1.69s/it, Loss=0.0485]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74/100 - Train Loss: 0.0531, Val Loss: 0.1233, Time: 8.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 75/100: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, Loss=0.0562]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75/100 - Train Loss: 0.0536, Val Loss: 0.1206, Time: 8.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 76/100: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it, Loss=0.0438]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76/100 - Train Loss: 0.0513, Val Loss: 0.1210, Time: 8.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 77/100: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it, Loss=0.0466]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77/100 - Train Loss: 0.0483, Val Loss: 0.1204, Time: 8.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 78/100: 100%|██████████| 3/3 [00:04<00:00,  1.39s/it, Loss=0.0670]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78/100 - Train Loss: 0.0561, Val Loss: 0.1231, Time: 8.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 79/100: 100%|██████████| 3/3 [00:05<00:00,  1.76s/it, Loss=0.0494]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79/100 - Train Loss: 0.0499, Val Loss: 0.1132, Time: 9.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 80/100: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, Loss=0.0510]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80/100 - Train Loss: 0.0547, Val Loss: 0.1118, Time: 9.1min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 81/100: 100%|██████████| 3/3 [00:05<00:00,  1.73s/it, Loss=0.0502]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81/100 - Train Loss: 0.0490, Val Loss: 0.1157, Time: 9.2min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 82/100: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it, Loss=0.0540]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82/100 - Train Loss: 0.0502, Val Loss: 0.1181, Time: 9.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 83/100: 100%|██████████| 3/3 [00:04<00:00,  1.44s/it, Loss=0.0477]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83/100 - Train Loss: 0.0498, Val Loss: 0.1189, Time: 9.4min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 84/100: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, Loss=0.0580]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84/100 - Train Loss: 0.0495, Val Loss: 0.1187, Time: 9.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 85/100: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it, Loss=0.0500]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85/100 - Train Loss: 0.0433, Val Loss: 0.1159, Time: 9.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 86/100: 100%|██████████| 3/3 [00:04<00:00,  1.62s/it, Loss=0.0461]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86/100 - Train Loss: 0.0477, Val Loss: 0.1138, Time: 9.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 87/100: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it, Loss=0.0459]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87/100 - Train Loss: 0.0454, Val Loss: 0.1152, Time: 9.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 88/100: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it, Loss=0.0401]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88/100 - Train Loss: 0.0401, Val Loss: 0.1170, Time: 9.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 89/100: 100%|██████████| 3/3 [00:04<00:00,  1.47s/it, Loss=0.0386]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89/100 - Train Loss: 0.0437, Val Loss: 0.1177, Time: 10.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 90/100: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it, Loss=0.0431]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90/100 - Train Loss: 0.0467, Val Loss: 0.1181, Time: 10.2min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 91/100: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it, Loss=0.0470]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91/100 - Train Loss: 0.0437, Val Loss: 0.1171, Time: 10.3min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 92/100: 100%|██████████| 3/3 [00:05<00:00,  1.72s/it, Loss=0.0468]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92/100 - Train Loss: 0.0505, Val Loss: 0.1156, Time: 10.4min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 93/100: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it, Loss=0.0546]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93/100 - Train Loss: 0.0428, Val Loss: 0.1154, Time: 10.5min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 94/100: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it, Loss=0.0517]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94/100 - Train Loss: 0.0425, Val Loss: 0.1155, Time: 10.6min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 95/100: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it, Loss=0.0522]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95/100 - Train Loss: 0.0391, Val Loss: 0.1158, Time: 10.7min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 96/100: 100%|██████████| 3/3 [00:04<00:00,  1.47s/it, Loss=0.0449]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96/100 - Train Loss: 0.0446, Val Loss: 0.1157, Time: 10.8min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 97/100: 100%|██████████| 3/3 [00:05<00:00,  1.71s/it, Loss=0.0325]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97/100 - Train Loss: 0.0420, Val Loss: 0.1155, Time: 10.9min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 98/100: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it, Loss=0.0474]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98/100 - Train Loss: 0.0447, Val Loss: 0.1160, Time: 11.0min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 99/100: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it, Loss=0.0434]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99/100 - Train Loss: 0.0434, Val Loss: 0.1164, Time: 11.1min\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 100/100: 100%|██████████| 3/3 [00:04<00:00,  1.47s/it, Loss=0.0370]\n","Validating: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100/100 - Train Loss: 0.0445, Val Loss: 0.1159, Time: 11.2min\n","Training completed! Best validation loss: 0.1094\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>learning_rate</td><td>█████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_epoch</td><td>▆▇█▇▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>step</td><td>297</td></tr><tr><td>train_loss_epoch</td><td>0.04452</td></tr><tr><td>train_loss_step</td><td>0.04889</td></tr><tr><td>val_loss_epoch</td><td>0.11595</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">unet-film-20250804-074813</strong> at: <a href='https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring/runs/uhdhzwbw' target=\"_blank\">https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring/runs/uhdhzwbw</a><br> View project at: <a href='https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring' target=\"_blank\">https://wandb.ai/meghashyam2005-mahindra-university/polygon-coloring</a><br>Synced 5 W&B file(s), 100 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250804_074855-uhdhzwbw/logs</code>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"e361e7f6","executionInfo":{"status":"ok","timestamp":1754294413153,"user_tz":-330,"elapsed":45,"user":{"displayName":"Megha Shyam","userId":"08441739143667292717"}},"outputId":"2a138b54-7326-4179-e12a-2b9e8485b2e5"},"source":["import os\n","from google.colab import files\n","\n","checkpoint_dir = 'checkpoints'\n","checkpoint_path = os.path.join(checkpoint_dir, 'best_checkpoint.pth')\n","\n","if os.path.exists(checkpoint_path):\n","    print(f\"Downloading {checkpoint_path}...\")\n","    files.download(checkpoint_path)\n","else:\n","    print(f\"Best checkpoint not found at {checkpoint_path}. Please ensure training completed successfully and the file exists.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading checkpoints/best_checkpoint.pth...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_c288973c-6f56-4b1d-86c8-75f951038032\", \"best_checkpoint.pth\", 212084054)"]},"metadata":{}}]}]}